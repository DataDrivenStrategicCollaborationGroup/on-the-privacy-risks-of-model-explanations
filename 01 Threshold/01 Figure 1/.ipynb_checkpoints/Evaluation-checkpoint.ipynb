{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "experiment_name = \"purchase\"\n",
    "cifar=False\n",
    "spilt=0.5\n",
    "experiment_numbers = np.arange(1)\n",
    "max_model_number = 4\n",
    "path=\"ThresholdExperiments/{}/{}\".format(experiment_name,random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(threshold,train,test,information_type):\n",
    "    if information_type ==\"prediction_var\":\n",
    "        return ((train >= threshold).sum() + (test < threshold).sum()) / (len(train)+len(test)) \n",
    "    else:\n",
    "        return ((train <= threshold).sum() + (test > threshold).sum()) / (len(train)+len(test))\n",
    "\n",
    "def read_model(path,model_number, information_type,cifar=False):\n",
    "    if not cifar:\n",
    "        df = pd.read_csv(\"{}/{}.csv\".format(path,model_number),index_col=0)\n",
    "        train = df[\"train_{}\".format(information_type)]\n",
    "        test = df[\"test_{}\".format(information_type)]\n",
    "    else:\n",
    "        df = pd.read_csv(\"{}/{}_train.csv\".format(path,model_number),index_col=0)\n",
    "        train = df[\"train_{}\".format(information_type)]\n",
    "        train = train.head(10000)\n",
    "        df = pd.read_csv(\"{}/{}_test.csv\".format(path,model_number),index_col=0)\n",
    "        test = df[\"test_{}\".format(information_type)]\n",
    "    return train, test\n",
    "\n",
    "def evaluate_optimal_attack(path,model_number,information_type,cifar=False):\n",
    "    train, test = read_model(path,model_number, information_type,cifar)\n",
    "    optimal_acc = 0\n",
    "    optimal_threshold = np.nan\n",
    "    sort_train = np.sort(np.unique(train))\n",
    "    #We're not looking at every possible thrshold but only every 10th, \n",
    "    #that speeds up computation by 10 times and doesn't seem to have\n",
    "    #effect on the performance\n",
    "    for threshold_ind in range(0,len(sort_train),10):\n",
    "        threshold = sort_train[threshold_ind]\n",
    "        acc = comparison(threshold,train,test,information_type)\n",
    "        if acc>optimal_acc:\n",
    "            optimal_acc = acc\n",
    "            optimal_threshold = threshold\n",
    "    return optimal_acc, optimal_threshold\n",
    "\n",
    "def evaluate_k_shadow_attack(path,model_number,information_type,k,cifar=False,max_model_number=4):\n",
    "    if cifar: return np.nan,np.nan\n",
    "    thresholds = np.zeros(k)\n",
    "    for current_k in range(k):\n",
    "        _, thresholds[current_k] = evaluate_optimal_attack(path,(model_number+1+k)% max_model_number,information_type)\n",
    "    threshold = np.median(thresholds)\n",
    "    train, test = read_model(path,model_number, information_type,cifar=cifar)\n",
    "    acc = comparison(threshold,train,test,information_type)\n",
    "    return acc, threshold     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_types = [\"loss\", \"prediction_var\", \"analysis_var\"]\n",
    "model_numbers = np.arange(max_model_number)\n",
    "result_accs, result_thresholds = {},{}\n",
    "attack_types = {'optimal':[],\"shadow_1\":[],\"shadow_3\":[]}\n",
    "for information_type in information_types:\n",
    "    result_accs[information_type] = copy.deepcopy(attack_types)\n",
    "    result_thresholds[information_type] = copy.deepcopy(attack_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase-smoothgrad "
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'ThresholdExperiments/purchase-smoothgrad/0//0_train.csv' does not exist: b'ThresholdExperiments/purchase-smoothgrad/0//0_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-b0ee1fd16a20>\u001b[0m in \u001b[0;36mevaluate_optimal_attack\u001b[0;34m(path, model_number, information_type, cifar)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_optimal_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minformation_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcifar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcifar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimal_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-b0ee1fd16a20>\u001b[0m in \u001b[0;36mread_model\u001b[0;34m(path, model_number, information_type, cifar)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minformation_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}_train.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minformation_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'ThresholdExperiments/purchase-smoothgrad/0//0_train.csv' does not exist: b'ThresholdExperiments/purchase-smoothgrad/0//0_train.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_model_number = 1\n",
    "cifar=True\n",
    "for experiment_name in [\"purchase-smoothgrad\"]:\n",
    "    information_types = [\"loss\", \"prediction_var\", \"analysis_var\", \"analysis_1\"]\n",
    "    model_numbers = np.arange(max_model_number)\n",
    "    result_accs, result_thresholds = {},{}\n",
    "    attack_types = {'optimal':[],\"shadow_1\":[],\"shadow_3\":[],\"split\":[]}\n",
    "    for information_type in information_types:\n",
    "        result_accs[information_type] = copy.deepcopy(attack_types)\n",
    "        result_thresholds[information_type] = copy.deepcopy(attack_types)\n",
    "    print(experiment_name, end=\" \")\n",
    "    counter = 0\n",
    "    start = time.time()\n",
    "    for experiment_numer in experiment_numbers:\n",
    "        path=\"ThresholdExperiments/{}/{}/\".format(experiment_name,experiment_numer)\n",
    "        for model_number in model_numbers:\n",
    "            #print(counter, end= \" \")\n",
    "            counter += 1\n",
    "            for information_type in information_types: \n",
    "                #print(information_type, end=\" \")\n",
    "                acc, threshold = evaluate_optimal_attack(path,model_number,information_type,cifar=cifar)\n",
    "                result_accs[information_type][\"optimal\"].append(acc)\n",
    "                result_thresholds[information_type][\"optimal\"].append(threshold)\n",
    "                acc, threshold = evaluate_k_shadow_attack(path,model_number,information_type,k=1,cifar=cifar,max_model_number=2)\n",
    "                result_accs[information_type][\"shadow_1\"].append(acc)\n",
    "                result_thresholds[information_type][\"shadow_1\"].append(threshold)\n",
    "                acc, threshold = evaluate_k_shadow_attack(path,model_number,information_type,k=3,cifar=cifar)\n",
    "                result_accs[information_type][\"shadow_3\"].append(acc)\n",
    "                result_thresholds[information_type][\"shadow_3\"].append(threshold)\n",
    "                acc, threshold = evaluate_split_attack(path,model_number,information_type,split=spilt,cifar=cifar)\n",
    "                result_accs[information_type][\"split\"].append(acc)\n",
    "                result_thresholds[information_type][\"split\"].append(threshold)\n",
    "    print(time.time() - start) \n",
    "    pickle.dump(result_accs,open(experiment_name+\"_accs\",\"bw\"))\n",
    "    pickle.dump(result_thresholds,open(experiment_name+\"_thrs\",\"bw\"))\n",
    "    for information_type in information_types: \n",
    "        print(information_type)\n",
    "        for attack_type in ['optimal\\t',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "            print(\"{}\\t\".format(attack_type),end=\" \")\n",
    "        print(\"\")\n",
    "        for attack_type in ['optimal',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "            print(\" {:.2f}\\t\\t\".format(np.mean(result_accs[information_type][attack_type])),end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "optimal\t\t shadow_1\t shadow_3\t split\t \n",
      " 0.62\t\t 0.62\t\t 0.51\t\t 0.60\t\t\n",
      "prediction_var\n",
      "optimal\t\t shadow_1\t shadow_3\t split\t \n",
      " 0.57\t\t 0.57\t\t 0.51\t\t 0.57\t\t\n",
      "analysis_var\n",
      "optimal\t\t shadow_1\t shadow_3\t split\t \n",
      " 0.51\t\t 0.51\t\t 0.51\t\t 0.51\t\t\n",
      "analysis_1\n",
      "optimal\t\t shadow_1\t shadow_3\t split\t \n",
      " 0.51\t\t 0.51\t\t 0.51\t\t 0.51\t\t\n"
     ]
    }
   ],
   "source": [
    "for information_type in information_types: \n",
    "    print(information_type)\n",
    "    for attack_type in ['optimal\\t',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "        print(\"{}\\t\".format(attack_type),end=\" \")\n",
    "    print(\"\")\n",
    "    for attack_type in ['optimal',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "        print(\" {:.2f}\\t\\t\".format(np.mean(result_accs[information_type][attack_type])),end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(result_accs,open(experiment_name+\"_accs\",\"bw\"))\n",
    "#pickle.dump(result_thresholds,open(experiment_name+\"_thrs\",\"bw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_accs = pickle.load(open(experiment_name+\"_accs\",\"br\"))\n",
    "result_thresholds = pickle.load(open(experiment_name+\"_thrs\",\"br\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar=False\n",
    "spilt=0.5\n",
    "experiment_numbers = np.arange(10)\n",
    "max_model_number = 1\n",
    "path=\"ThresholdExperiments/{}/{}\".format(experiment_name,random_state)\n",
    "purchase_other_experiments = [\"purchase-shiftgrad\", \"purchase\",\"purchase-smoothgrad\", \"purchase-guided_backprop\",\"purchase-integrated_gradients\", \"purchase-lrp\"]\n",
    "texas_other_experiments = [\"texas\",\"texas-smoothgrad\", \"texas-guided_backprop\",\"texas-integrated_gradients\", \"texas-lrp\"]\n",
    "cifar_10_other_experiments = [\"cifar-10\",\"cifar-10-smoothgrad\", \"cifar-10-guided_backprop\",\"cifar-10-integrated_gradients\", \"cifar-10-lrp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10 optimal\t\t shadow_1\t shadow_3\t split\t 34.55970621109009\n",
      "analysis_var\t0.52\t\t 0.52\t\t 0.52\t\t 0.52\t\t \n",
      "cifar-10-smoothgrad optimal\t\t shadow_1\t shadow_3\t split\t 34.85753011703491\n",
      "analysis_var\t0.53\t\t 0.53\t\t 0.53\t\t 0.52\t\t \n",
      "cifar-10-guided_backprop optimal\t\t shadow_1\t shadow_3\t split\t 34.84765005111694\n",
      "analysis_var\t0.50\t\t 0.50\t\t 0.50\t\t 0.46\t\t \n",
      "cifar-10-integrated_gradients optimal\t\t shadow_1\t shadow_3\t split\t 34.87642288208008\n",
      "analysis_var\t0.52\t\t 0.52\t\t 0.52\t\t 0.52\t\t \n",
      "cifar-10-lrp optimal\t\t shadow_1\t shadow_3\t split\t 34.83699679374695\n",
      "analysis_var\t0.52\t\t 0.52\t\t 0.52\t\t 0.52\t\t \n",
      "CPU times: user 2min 53s, sys: 763 ms, total: 2min 53s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for experiment_name in cifar_10_other_experiments:\n",
    "    information_types = [\"loss\", \"prediction_var\", \"analysis_var\"]\n",
    "    model_numbers = np.arange(max_model_number)\n",
    "    result_accs, result_thresholds = {},{}\n",
    "    attack_types = {'optimal':[],\"shadow_1\":[],\"shadow_3\":[],\"split\":[]}\n",
    "    for information_type in information_types:\n",
    "        result_accs[information_type] = copy.deepcopy(attack_types)\n",
    "        result_thresholds[information_type] = copy.deepcopy(attack_types)\n",
    "    print(experiment_name, end=\" \")\n",
    "    for attack_type in ['optimal\\t',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "            print(\"{}\\t\".format(attack_type),end=\" \")\n",
    "    counter = 0\n",
    "    start = time.time()\n",
    "    for experiment_numer in experiment_numbers:\n",
    "        path=\"ThresholdExperiments/{}/{}/\".format(experiment_name,experiment_numer)\n",
    "        for model_number in model_numbers:\n",
    "            #print(counter, end= \" \")\n",
    "            counter += 1\n",
    "            for information_type in [\"analysis_var\"]: \n",
    "                #print(information_type, end=\" \")\n",
    "                acc, threshold = evaluate_optimal_attack(path,model_number,information_type,cifar=cifar)\n",
    "                result_accs[information_type][\"optimal\"].append(acc)\n",
    "                result_thresholds[information_type][\"optimal\"].append(threshold)\n",
    "                acc, threshold = evaluate_k_shadow_attack(path,model_number,information_type,k=1,cifar=cifar,max_model_number=2)\n",
    "                result_accs[information_type][\"shadow_1\"].append(acc)\n",
    "                result_thresholds[information_type][\"shadow_1\"].append(threshold)\n",
    "                acc, threshold = evaluate_k_shadow_attack(path,model_number,information_type,k=3,cifar=cifar)\n",
    "                result_accs[information_type][\"shadow_3\"].append(acc)\n",
    "                result_thresholds[information_type][\"shadow_3\"].append(threshold)\n",
    "                acc, threshold = evaluate_split_attack(path,model_number,information_type,split=spilt,cifar=cifar)\n",
    "                result_accs[information_type][\"split\"].append(acc)\n",
    "                result_thresholds[information_type][\"split\"].append(threshold)\n",
    "    print(time.time() - start) \n",
    "    pickle.dump(result_accs,open(experiment_name+\"_accs\",\"bw\"))\n",
    "    pickle.dump(result_thresholds,open(experiment_name+\"_thrs\",\"bw\"))\n",
    "    for information_type in [\"analysis_var\"]: \n",
    "        print(information_type, end=\"\\t\")\n",
    "        if information_type == \"loss\":\n",
    "            print(\"\\t\",end=\"\")\n",
    "        for attack_type in ['optimal',\"shadow_1\",\"shadow_3\",\"split\"]:\n",
    "            print(\"{:.2f}\\t\\t\".format(np.mean(result_accs[information_type][attack_type])),end=\" \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for increasing number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar=False\n",
    "experiment_numbers = np.arange(5)\n",
    "max_model_number = 1\n",
    "experiment_name = \"texas-epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.55\t\t \n",
      "10 0.59\t\t \n",
      "15 0.61\t\t \n",
      "20 0.64\t\t \n",
      "25 0.64\t\t \n",
      "30 0.64\t\t \n",
      "35 0.66\t\t \n",
      "40 0.66\t\t \n",
      "45 0.66\t\t \n",
      "CPU times: user 18.7 s, sys: 88 ms, total: 18.7 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epochs in range(5,50,5):\n",
    "    information_types = [\"analysis_var\"]\n",
    "    model_numbers = np.arange(max_model_number)\n",
    "    result_accs, result_thresholds = {},{}\n",
    "    attack_types = {'optimal':[]}\n",
    "    for information_type in information_types:\n",
    "        result_accs[information_type] = copy.deepcopy(attack_types)\n",
    "        result_thresholds[information_type] = copy.deepcopy(attack_types)\n",
    "    print(epochs, end=\" \")\n",
    "    #for attack_type in ['optimal\\t']:\n",
    "            #print(\"{}\\t\".format(attack_type),end=\" \")\n",
    "    counter = 0\n",
    "    start = time.time()\n",
    "    for experiment_number in experiment_numbers:\n",
    "        path=\"ThresholdExperiments/{}/{}_{}/\".format(experiment_name,experiment_number,epochs)\n",
    "        for model_number in model_numbers:\n",
    "            #print(counter, end= \" \")\n",
    "            counter += 1\n",
    "            for information_type in [\"analysis_var\"]: \n",
    "                #print(information_type, end=\" \")\n",
    "                acc, threshold = evaluate_optimal_attack(path,model_number,information_type,cifar=cifar)\n",
    "                result_accs[information_type][\"optimal\"].append(acc)\n",
    "                result_thresholds[information_type][\"optimal\"].append(threshold)\n",
    "    #print(time.time() - start) \n",
    "    pickle.dump(result_accs,open(experiment_name+\"_accs\",\"bw\"))\n",
    "    pickle.dump(result_thresholds,open(experiment_name+\"_thrs\",\"bw\"))\n",
    "    for information_type in [\"analysis_var\"]: \n",
    "        #print(information_type, end=\"\\t\")\n",
    "        if information_type == \"loss\":\n",
    "            print(\"\\t\",end=\"\")\n",
    "        for attack_type in ['optimal']:\n",
    "            print(\"{:.2f}\\t\\t\".format(np.mean(result_accs[information_type][attack_type])),end=\" \")\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
